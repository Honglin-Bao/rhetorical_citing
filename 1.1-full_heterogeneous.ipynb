{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPyYZaPSjY4lr5THxGcMmZb"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["#heterogeneous quality + heterogeneous rhetorical value full model\n","\n","import random\n","import numpy as np\n","random.seed(100000)\n","np.random.seed(100000)\n","#fix random seeds across six models to make results exactly reproducible\n","#average across a large number of fixed-seed runs and get average effects/error bands, etc.\n","#this is because we want to ensure that\n","#observed differences between models\n","#are due to the mechanisms we proposed and not random variations between comparison experiments\n","\n","import scipy.stats as stats\n","from scipy.stats import pearsonr\n","from scipy.stats import norm\n","\n","#helper function for calculating Gini coefficient\n","def gini_coefficient(x):\n","    \"\"\"Compute Gini coefficient of array of values\"\"\"\n","    diffsum = 0\n","    for i, xi in enumerate(x[:-1], 1):\n","        diffsum += np.sum(np.abs(xi - x[i:]))\n","    return diffsum / (len(x)**2 * np.mean(x))\n","\n","#helper function for getting indices of the top N values of a list (which to read/cite)\n","def f(a,N):\n","    \"\"\"Get indices of the top N values of a list\"\"\"\n","    return np.argsort(a)[::-1][:N]\n","\n","#args need to use\n","tmax= 1000#time steps\n","#-----------------------------\n","num = 600#paper population\n","nummax=600 #by varying field size\n","#key variable of interest\n","#-----------------------------\n","reference = 20#expected reference size, need to vary\n","refmax =100  #by varying reference size\n","#key variable of interest\n","#-----------------------------\n","reading = 120#reading size, need to vary\n","readingmax=120 #by varying reading size\n","#key variable of interest\n","#-----------------------------\n","noise =0.05\n","#tested for robustness (see Appendix 1.3)\n","\n","fit =0.1\n","#tested for robustness (see Appendix 1.4)\n","\n","shape =6#shape for value distribution\n","#tested for robustness (see Appendix 1.1)\n","\n","listcorr=[] #correlation (citation-quality)\n","listgini=[] #gini\n","#figure 2, in what way top-quality/mid-quality papers are cited? (substantive or rhetorical)\n","list1=[] #top papers cited substantively\n","list2=[] #top papers cited rhetorically\n","list3=[] #mid papers cited substantively\n","list4=[] #mid papers cited rhetorically\n","\n","for num in range(num, nummax+1): #varying field size\n","  normative=np.random.beta(1, shape, size=num)\n","  qrank =[]\n","  qrank = list(np.argsort(normative)[-(num):][::-1]) #quality distribution and its rank\n","\n","#-------------------------------------------------------------------------------\n","  #move to the model\n","  weight=0.001 #the weight of citation count on perceived quality\n","  weightq =0.3#the signal-based gain in rhetoric value\n","  #tested for robustness (see Appendix 1.5: reinforcing process)\n","\n","  for reference in range(reference, refmax+1):\n","  #for reading in range(reading, readingmax+1):\n","\n","    top1q=qrank[0:40]# top 40 quality (high quality)\n","    top2q=qrank[40:int(150)]# top 40-150 quality (mid-to-high quality) /600 in total\n","\n","    cite_population = [0]*num #citation count over the entire paper population, initial as 0\n","    rhe_list=[0]*num #rhetoric value, initial as 0\n","    chunk =[] #citation churn\n","\n","    for t in range(1, tmax+1): #a reader joins\n","    #heterogeneous quality: the reader has her own perception of--\n","    #--threshold/fit/error/underlying rhetorical value\n","    #initialize them within the loop\n","\n","      threshold =random.uniform(0,1)\n","      #normal distribution of threshold for robustness\n","      #we tested robustness (see Appendix 1.2)\n","      #mu, sigma = 0.5, 0.2# for high peak\n","      #lower, upper = 0, 1\n","      #X1 = stats.truncnorm(\n","      #  (lower - mu) / sigma, (upper - mu) / sigma, loc=mu, scale=sigma)\n","      #threshold1=X1.rvs(1)\n","      #threshold =threshold1[0]\n","\n","      #underlying rhetorical value is heterogeneous\n","      base_rhe=np.random.beta(1, shape, size=num)\n","\n","      noise_list=np.random.normal(0, noise, num)\n","      #we tested it for robustness (see Appendix 1.3)\n","\n","      #fit - heterogeneous\n","      fit_list=[]\n","      for i in range(num):\n","        fit_list.append(random.uniform(-fit, fit))\n","      #tested for robustness (see Appendix 1.4)\n","\n","      #perceived quality signal\n","      signal =[]\n","      for i in range(num):\n","        #0-1 cut off\n","        signal.append(normative[i]+ fit_list[i] + weight * cite_population[i] + noise_list[i])\n","      for i in range(num):\n","        if (signal[i] >2): #maximum 2, quality +fit +error =1, weight * citation (citation premium) =1\n","          signal[i] =2\n","        if (signal[i] <0):\n","          signal[i] =0 #non-negative\n","\n","      #reading size\n","      reading_index = list(np.argsort(signal)[-(reading):][::-1])#read papers with the highest perceived quality\n","\n","      #overall rhetorical values ==\n","      #underlying rhetorical value + ...\n","      #...weight_on_perceived_quality * (quality + fit + citation permium), in the *read* list (so no error)\n","      for i in range(len(reading_index)):\n","        rhe_list[reading_index[i]] =base_rhe[reading_index[i]] + weightq* fit_list[reading_index[i]] + weightq*normative[reading_index[i]] + weightq* weight*cite_population[reading_index[i]]\n","\n","      #if unread\n","      #overall rhetorical values == underlying rhetorical value + ...\n","      #...weight_on_perceived_quality * (quality + fit + citation premium + error (noise_list))\n","      unread=[]\n","      unread = [i for i in list(range(0,num)) if i not in reading_index]\n","      for i in range(len(unread)):\n","        rhe_list[unread[i]] =base_rhe[unread[i]] + weightq* fit_list[unread[i]] + weightq*normative[unread[i]] + weightq* weight*cite_population[unread[i]] + weightq* noise_list[unread[i]]\n","\n","      #truncted overall rhetorical value\n","      #min ==0\n","      #max == maximum underlying rhetorical value (1) + ...\n","      #...weight_on_perceived_quality * perceived quality [1(quality + fit + error) + 1(citation premium)]\n","      #see table 1 in the original paper\n","      for i in range(num):\n","        if (rhe_list[i] <0):\n","          rhe_list[i] =0\n","        if(rhe_list[i] > 1+ weightq+ weightq):\n","          rhe_list[i] =1+ weightq+ weightq\n","\n","      #after reading, the error disappears, so quality in eyes = quality + fit\n","      norm_list =[]\n","      for i in range(len(reading_index)):\n","        norm_list.append(normative[reading_index[i]] + fit_list[reading_index[i]])\n","\n","      #quality in eyes = quality + fit range [0,1]\n","      for i in range(len(reading_index)):\n","        if (norm_list[i] <0):\n","          norm_list[i] =0\n","        if (norm_list[i] >1):\n","          norm_list[i] =1\n","\n","      #which one is beyond the substantive citing threshold?\n","      over_threshold=[]\n","      for i in range(len(norm_list)):\n","        if (norm_list[i]> threshold):\n","          over_threshold.append(reading_index[i])\n","\n","      normative_cite=[]# substantive citation list\n","      rhetorical_cite=[]# rhetorical citation list\n","      overlap=[]#overlap between substantive and rhetorical citing\n","      overall_cite =[]\n","\n","      #if there are enough good papers for substantive citing\n","      #then all cites are substantive (cite the best ones within the citing budget)\n","      #update citation counts -- and the impact that citations induce\n","      if (len(over_threshold) >= reference):\n","        cite = list(f(norm_list, reference))\n","        for i in range(len(cite)):\n","          cite_population[reading_index[cite[i]]]= cite_population[reading_index[cite[i]]]+1\n","          normative_cite.append(reading_index[cite[i]])\n","        rhetorical_cite=[]\n","        overlap =[]\n","        overall_cite = normative_cite + rhetorical_cite + overlap\n","\n","      #if there are insufficient good papers for substantive citing\n","      #first, cite all of these good ones substantively as \"normative_cite\"\n","      else:\n","        normative_cite = over_threshold.copy()\n","        #how many slots are left -- we fill up all of them according to the overall rhetorical values\n","        rhetoric_no = reference - len(over_threshold)\n","        new_rhe = rhe_list.copy()\n","        rhe2=[]\n","        rhe2 = sorted(new_rhe, reverse = True)\n","        itr=0\n","        itr2=0\n","        while (itr < rhetoric_no):\n","          #a small proportion of papers first is cited substantively\n","          #then if people find them rhetorically useful as well\n","          #move them into the set of \"overlap\" --\n","          #cited both substantively and rhetorically (we allow this which is the case in the real world)\n","\n","          if ((new_rhe.index(rhe2[itr2]) in normative_cite) == True):\n","            normative_cite.remove(new_rhe.index(rhe2[itr2]))\n","            numitr = new_rhe.index(rhe2[itr2])\n","            overlap.append(numitr)\n","            itr2 =itr2+1\n","          else:\n","            rhetorical_cite.append(new_rhe.index(rhe2[itr2]))\n","            itr =itr+1\n","            itr2 =itr2+1\n","\n","        #update citation count\n","        overall_cite = normative_cite + rhetorical_cite + overlap\n","        for i in range(len(overall_cite)):\n","          cite_population[overall_cite[i]] = cite_population[overall_cite[i]] +1\n","      #churn\n","      #this round, which papers get cited?\n","      chunk.append(overall_cite)\n","\n","#here, experiments--------------------------------------------------------------\n","      #figure 2: how are two groups (high quality VS mid quality) of papers cited in different models?\n","      #top1=0\n","      #for i in range(40):\n","      # if ((top1q[i] in (normative_cite + overlap)) == True):\n","      #    top1 = top1+1\n","      #list1.append(top1/reference)\n","      #top2=0\n","      #for i in range(40):\n","      #  if ((top1q[i] in (rhetorical_cite + overlap)) == True):\n","      #    top2 = top2+1\n","      #list2.append(top2/reference)\n","      #top3=0\n","      #for i in range(110):\n","      #  if ((top2q[i] in (normative_cite + overlap)) == True):\n","      #    top3 = top3+1\n","      #list3.append(top3/reference)\n","     # top4=0\n","      #for i in range(110):\n","      #   if ((top2q[i] in (rhetorical_cite + overlap)) == True):\n","      #    top4 = top4+1\n","      #list4.append(top4/reference)\n","\n","    #print(*cite_population, sep='\\n') #every round the citation count distribution\n","\n","    #listgini.append(gini_coefficient(np.array(cite_population))) #gini coefficient\n","\n","    corr1, _ = stats.pearsonr(normative, cite_population)\n","    listcorr.append(corr1) #citation-quality correlation, example output\n","\n","    # churn, which is the newly cited papers compared to the last round\n","    #dnew=[]\n","    #for i in range(len(chunk) -1):\n","    #  a=0\n","     # for j in range(len(chunk[i+1])):\n","     #   if ((chunk[i+1][j] in chunk[i]) == False):\n","     #     a=a+1\n","      #dnew.append(a)\n","    #print(np.mean(dnew))\n","\n","#print(list1)\n","#print(list2)\n","#print(list3)\n","#print(list4)\n","print('example output: Correlation (citation-quality)')\n","print(*listcorr, sep='\\n')\n","print('the full model\\'s correlation is higher than either null models')\n","#print(listgini)"],"metadata":{"id":"19qlh6GI5eS8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1693765188915,"user_tz":240,"elapsed":468840,"user":{"displayName":"Honglin Bao","userId":"14286809748787468687"}},"outputId":"60df603c-249e-429c-f643-14254e802278"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["example output: Correlation (citation-quality)\n","0.6836293522666834\n","0.696374430127724\n","0.7013635474254413\n","0.7059455212382381\n","0.715919561504083\n","0.7221730505784769\n","0.7268020772055044\n","0.7349468471921673\n","0.741802858120647\n","0.7462776172783917\n","0.7526300688954846\n","0.7608874242970943\n","0.7614715822026559\n","0.7677739619582702\n","0.7730344947412569\n","0.7781479266672098\n","0.7813029530685538\n","0.7863997064037257\n","0.7919528445944846\n","0.7948991690441161\n","0.8010161863744167\n","0.8044901530268589\n","0.811284593242172\n","0.8098364572980024\n","0.8143138512026423\n","0.8184007038207295\n","0.8159597225504489\n","0.8245640009852617\n","0.8280352757427344\n","0.8320036140699847\n","0.8330913665122204\n","0.8354360544352559\n","0.8387071981454703\n","0.8438777865094035\n","0.846125881283999\n","0.8501523013890638\n","0.8547232109288513\n","0.8536824553499324\n","0.8557236460252265\n","0.861086974934922\n","0.8637619377034851\n","0.8655696353363695\n","0.8697167921903648\n","0.8715036279884668\n","0.8736914917481844\n","0.8748366326936343\n","0.8777770115014641\n","0.8802989699019195\n","0.8800265597186165\n","0.8855013841430374\n","0.888375776816877\n","0.885889615011556\n","0.8851708771055605\n","0.8921359054474836\n","0.8920730018608243\n","0.8968585883392654\n","0.8975737139006275\n","0.8991631639978841\n","0.8985524443636819\n","0.8998594514450143\n","0.9049928922705228\n","0.9032879916319022\n","0.9032080180236361\n","0.9064962909440218\n","0.9101403955873593\n","0.9113645880284373\n","0.9118581506602357\n","0.9125277086579718\n","0.9134223888025422\n","0.9140678861097972\n","0.9157667821433637\n","0.9168241916309945\n","0.9176944122602082\n","0.9192790787542555\n","0.9198972776853588\n","0.9209284994478568\n","0.9211180547681306\n","0.9202584219979091\n","0.9233521876910739\n","0.9230573311878704\n","0.9247252289891379\n","the full model's correlation is higher than either null models\n"]}]}]}