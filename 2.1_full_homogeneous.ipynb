{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPBFLjy969mcSlu1SKcd8NV"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gD0d3oNE2K4K","executionInfo":{"status":"ok","timestamp":1693767265942,"user_tz":240,"elapsed":3733,"user":{"displayName":"Honglin Bao","userId":"14286809748787468687"}},"outputId":"6c47a6fd-6724-42d3-9cff-7f6a0db2cf2b"},"outputs":[{"output_type":"stream","name":"stdout","text":["example output: the citation distribution after 1000 time steps:\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","1000\n","0\n","0\n","0\n","0\n","1000\n","0\n","0\n","0\n","64\n","0\n","0\n","0\n","1000\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","1000\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","996\n","1000\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","995\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","1000\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","1000\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","1000\n","0\n","0\n","0\n","0\n","0\n","1000\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","1000\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","1000\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","972\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","1000\n","0\n","0\n","0\n","1000\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","1000\n","1000\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","7\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","980\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","1000\n","0\n","0\n","0\n","1000\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","994\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","1000\n","0\n","0\n","0\n","0\n","1000\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","1000\n","0\n","0\n","0\n","0\n","1000\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","1000\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","1000\n","0\n","0\n","0\n","0\n","0\n","999\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","960\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","1000\n","0\n","0\n","0\n","0\n","0\n","982\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","1000\n","1000\n","0\n","0\n","0\n","0\n","0\n","1000\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","1000\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","1000\n","0\n","0\n","0\n","1000\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","18\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","1000\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","8\n","1000\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","25\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n","0\n"]}],"source":["#model 2-1: homogeneous quality + homogeneous rhetoric\n","import random\n","import numpy as np\n","random.seed(100000)\n","np.random.seed(100000)\n","import scipy.stats as stats\n","from scipy.stats import pearsonr\n","from scipy.stats import norm\n","\n","#helper function for calculating Gini coefficient\n","def gini_coefficient(x):\n","    \"\"\"Compute Gini coefficient of array of values\"\"\"\n","    diffsum = 0\n","    for i, xi in enumerate(x[:-1], 1):\n","        diffsum += np.sum(np.abs(xi - x[i:]))\n","    return diffsum / (len(x)**2 * np.mean(x))\n","\n","#helper function for getting indices of the top N values of a list (which to read/cite)\n","def f(a,N):\n","    \"\"\"Get indices of the top N values of a list\"\"\"\n","    return np.argsort(a)[::-1][:N]\n","\n","#args you need to use\n","tmax= 1000#time steps\n","#-----------------------------\n","num = 600#paper population\n","nummax=600\n","#-----------------------------\n","reference = 40#expected reference size, need to vary\n","refmax =40\n","#-----------------------------\n","reading = 120#reading size, need to vary\n","readingmax=120\n","#-----------------------------\n","noise =0.05\n","#-----------------------------\n","shape=6\n","\n","listcorr=[]\n","listgini=[]\n","threshold=0.5 #homogeneous threshold\n","\n","for num in range(num, nummax+1):\n","  normative=np.random.beta(1, shape, size=num)\n","  qrank =[]\n","  qrank = list(np.argsort(normative)[-(num):][::-1])\n","\n","#-------------------------------------------------------------------------------\n","#here is the major difference from model 1.1\n","#underlying rhetorical value is homogeneous and perceived equally\n","#thus it is outside the t loop (reader loop)\n","  base_rhe=np.random.beta(1, shape, size=num)\n","  rrank =[]\n","  rrank = list(np.argsort(base_rhe)[-(num):][::-1])\n","\n","  #move to the model\n","  weight=0.001 #the weight of citation count on perceived quality\n","  weightq =0.3 #the signal-based gain in rhetoric value\n","\n","  list1=[]\n","  list2=[]\n","  list3=[]\n","  list4=[]\n","\n","  for reference in range(reference, refmax+1):\n","  #for reading in range(reading, readingmax+1):\n","    top1q=qrank[0:40]\n","    top2q=qrank[40:int(150)]\n","\n","    cite_population = [0]*num #citation count over the entire paper population\n","    rhe_list=[0]*num #rhetoric value\n","    chunk =[]\n","\n","    for t in range(1, tmax+1):\n","\n","      noise_list=np.random.normal(0, noise, num)\n","      #here, noise is random, so it's within the loop of t (readers)\n","\n","      signal =[]\n","      for i in range(num):\n","        signal.append(normative[i]+ weight * cite_population[i] + noise_list[i])\n","      #no fit -- because fit is specific for heterogeneous models\n","\n","      for i in range(num):\n","        if(signal[i] >2):\n","          signal[i] =2\n","        if(signal[i] <0):\n","          signal[i]=0\n","\n","      reading_index = list(np.argsort(signal)[-(reading):][::-1])\n","\n","      for i in range(len(reading_index)):\n","        rhe_list[reading_index[i]] =base_rhe[reading_index[i]] + weightq*normative[reading_index[i]] + weightq* weight*cite_population[reading_index[i]]\n","\n","      unread=[]\n","      unread = [i for i in list(range(0,num)) if i not in reading_index]\n","      for i in range(len(unread)):\n","        rhe_list[unread[i]] =base_rhe[unread[i]] + weightq*normative[unread[i]] + weightq* weight*cite_population[unread[i]] + weightq* noise_list[unread[i]]\n","\n","      for i in range(num):\n","        if (rhe_list[i] <0):\n","          rhe_list[i] =0\n","        if(rhe_list[i] > 1+ weightq+ weightq):\n","          rhe_list[i] =1+ weightq+ weightq\n","\n","      norm_list =[]\n","      for i in range(len(reading_index)):\n","        norm_list.append(normative[reading_index[i]])\n","      for i in range(len(reading_index)):\n","        if (norm_list[i] <0):\n","          norm_list[i] =0\n","        if (norm_list[i] >1):\n","          norm_list[i] =1\n","\n","      over_threshold=[]\n","      for i in range(len(norm_list)):\n","        if (norm_list[i]> threshold):\n","          over_threshold.append(reading_index[i])\n","\n","      normative_cite=[]# substantive citation list\n","      rhetorical_cite=[]# rhetorical citation list\n","      overlap=[]#overlap\n","      overall_cite =[]\n","\n","      if (len(over_threshold) >= reference):\n","        cite = list(f(norm_list, reference))\n","        for i in range(len(cite)):\n","          cite_population[reading_index[cite[i]]]= cite_population[reading_index[cite[i]]]+1\n","          normative_cite.append(reading_index[cite[i]])\n","        rhetorical_cite=[]\n","        overlap =[]\n","        overall_cite = normative_cite + rhetorical_cite + overlap\n","\n","      else:\n","        normative_cite = over_threshold.copy()\n","        rhetoric_no = reference - len(over_threshold)\n","        new_rhe = rhe_list.copy()\n","        rhe2=[]\n","        rhe2 = sorted(new_rhe, reverse = True)\n","        itr=0\n","        itr2=0\n","        while (itr < rhetoric_no):\n","          if ((new_rhe.index(rhe2[itr2]) in normative_cite) == True):\n","            normative_cite.remove(new_rhe.index(rhe2[itr2]))\n","            numitr = new_rhe.index(rhe2[itr2])\n","            overlap.append(numitr)\n","            itr2 =itr2+1\n","          else:\n","            rhetorical_cite.append(new_rhe.index(rhe2[itr2]))\n","            itr =itr+1\n","            itr2 =itr2+1\n","        overall_cite = normative_cite + rhetorical_cite + overlap\n","        for i in range(len(overall_cite)):\n","          cite_population[overall_cite[i]] = cite_population[overall_cite[i]] +1\n","      #churn\n","      chunk.append(overall_cite)\n","\n","#here, experiments--------------------------------------------------------------\n","    #listgini.append(gini_coefficient(np.array(cite_population)))\n","    #corr1, _ = stats.pearsonr(normative, cite_population)\n","    #listcorr.append(corr1)\n","\n","      #top1=0\n","      #for i in range(40):\n","      # if ((top1q[i] in (normative_cite + overlap)) == True):\n","      #    top1 = top1+1\n","      #list1.append(top1/reference)\n","\n","      #top2=0\n","      #for i in range(40):\n","      #  if ((top1q[i] in (rhetorical_cite + overlap)) == True):\n","      #    top2 = top2+1\n","      #list2.append(top2/reference)\n","\n","      #top3=0\n","      #for i in range(110):\n","      #  if ((top2q[i] in (normative_cite + overlap)) == True):\n","      #    top3 = top3+1\n","      #list3.append(top3/reference)\n","\n","     # top4=0\n","      #for i in range(110):\n","      #   if ((top2q[i] in (rhetorical_cite + overlap)) == True):\n","      #    top4 = top4+1\n","      #list4.append(top4/reference)\n","\n","    #dnew=[]\n","    #for i in range(len(chunk) -1):\n","    #  a=0\n","    #  for j in range(len(chunk[i+1])):\n","    #    if ((chunk[i+1][j] in chunk[i]) == False):\n","    #      a=a+1\n","    #  dnew.append(a)\n","    #print(np.mean(dnew))\n","\n","#print(list1)\n","#print(list2)\n","#print(list3)\n","#print(list4)\n","#print(listcorr)\n","#print(listgini)\n","print('example output: the citation distribution after 1000 time steps:')\n","print(*cite_population, sep='\\n')"]},{"cell_type":"markdown","source":["In the homogeneous model, after 1000 iterations, the distribution is nearly bimodal with some papers having 0 citations and some 1000. Given that citation distributions in practice are never bimodal, we do not believe such a simple model is sufficiently realistic. For completeness, we present all three community health metrics for the three versions of this model (Full, Null-reference, Null-threshold) in Appendix Figure S13, but do not interpret it further."],"metadata":{"id":"P-PLImwUGDdd"}}]}